{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "06eb2db5",
      "metadata": {
        "id": "06eb2db5"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1VV2e_u46fNm_ewns8QW2HGRZAPHh-e2t\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb006272",
      "metadata": {
        "id": "fb006272"
      },
      "source": [
        "# **Diseño e implementación experimental**\n",
        "---\n",
        "\n",
        "Este notebook es una plantilla que le puede servir como guía para el tercer entregable del proyecto aplicado."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Proyecto aplicado por:\n",
        "\n",
        "\n",
        "*   Cristhian David Mora Uribe cdmorau@unal.edu.co\n",
        "*   Martin Camilo Rodriguez Murcia mrodriguezmu@unal.edu.co\n",
        "*   Nestor Steven Negrete Pinilla narutones98@gmail.com"
      ],
      "metadata": {
        "id": "dta5FqcXT9tr"
      },
      "id": "dta5FqcXT9tr"
    },
    {
      "cell_type": "markdown",
      "id": "cd5bb0b6",
      "metadata": {
        "id": "cd5bb0b6"
      },
      "source": [
        "## **1. Particion del conjunto de datos**\n",
        "---\n",
        "\n",
        "Si el dataset no tiene por defecto definida una partición en conjuntos de entrenamiento y prueba, hágala usted, en las proporciones que considere oportunas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---**INGRESE SU CÓDIGO**---\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/DeepLearning/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# Descargar el dataset de \"Twitter Financial News\" desde Kaggle y extraerlo\n",
        "!kaggle datasets download sudalairajkumar/cryptocurrencypricehistory"
      ],
      "metadata": {
        "id": "I46TkZXyYe1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852c3364-f4d2-4f73-c98e-0413f629edee"
      },
      "id": "I46TkZXyYe1b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset URL: https://www.kaggle.com/datasets/sudalairajkumar/cryptocurrencypricehistory\n",
            "License(s): CC0-1.0\n",
            "Downloading cryptocurrencypricehistory.zip to /content\n",
            "  0% 0.00/1.70M [00:00<?, ?B/s]\n",
            "100% 1.70M/1.70M [00:00<00:00, 177MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "# Extraer el archivo zip descargado\n",
        "with zipfile.ZipFile(\"/content/cryptocurrencypricehistory.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/crypto_data\")\n",
        "\n",
        "# Ruta donde están los archivos extraídos\n",
        "folder_path = \"/content/crypto_data/\"\n",
        "\n",
        "# Lista de los archivos CSV que quieres leer\n",
        "file_names = [\n",
        "    \"coin_Aave.csv\", \"coin_BinanceCoin.csv\", \"coin_Bitcoin.csv\", \"coin_Cardano.csv\",\n",
        "    \"coin_ChainLink.csv\", \"coin_Cosmos.csv\", \"coin_CryptocomCoin.csv\", \"coin_Dogecoin.csv\",\n",
        "    \"coin_EOS.csv\", \"coin_Ethereum.csv\", \"coin_Iota.csv\", \"coin_Litecoin.csv\",\n",
        "    \"coin_Monero.csv\", \"coin_NEM.csv\", \"coin_Polkadot.csv\", \"coin_Solana.csv\",\n",
        "    \"coin_Stellar.csv\", \"coin_Tether.csv\", \"coin_Tron.csv\", \"coin_USDCoin.csv\",\n",
        "    \"coin_Uniswap.csv\", \"coin_WrappedBitcoin.csv\", \"coin_XRP.csv\"\n",
        "]\n",
        "\n",
        "# Diccionario para almacenar los DataFrames\n",
        "dataframes = {}\n",
        "\n",
        "# Leer cada archivo CSV y almacenarlo en el diccionario\n",
        "for file in file_names:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    coin_name = file.replace(\"coin_\", \"\").replace(\".csv\", \"\")  # Extraer el nombre de la criptomoneda\n",
        "    dataframes[coin_name] = pd.read_csv(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "5Urwk9KoUYAT"
      },
      "id": "5Urwk9KoUYAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "bitcoin_data = dataframes['Bitcoin']\n",
        "\n",
        "bitcoin_data['Date'] = pd.to_datetime(bitcoin_data['Date'])\n",
        "bitcoin_data = bitcoin_data.sort_values('Date')\n",
        "\n",
        "# Definir las características y la variable objetivo\n",
        "X = bitcoin_data[['Open', 'High', 'Low', 'Volume']]  # Características\n",
        "y = bitcoin_data['Close']  # Variable objetivo\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=False)\n",
        "\n",
        "print(\"Conjunto de Entrenamiento:\")\n",
        "print(X_train.head())\n",
        "print(\"\\nConjunto de Prueba:\")\n",
        "print(X_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SSCGQEQWVIV",
        "outputId": "282363a1-ee0c-4a1f-894c-998cc76fd009"
      },
      "id": "2SSCGQEQWVIV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conjunto de Entrenamiento:\n",
            "         Open        High         Low  Volume\n",
            "0  134.444000  147.488007  134.000000     0.0\n",
            "1  144.000000  146.929993  134.050003     0.0\n",
            "2  139.000000  139.889999  107.720001     0.0\n",
            "3  116.379997  125.599998   92.281898     0.0\n",
            "4  106.250000  108.127998   79.099998     0.0\n",
            "\n",
            "Conjunto de Prueba:\n",
            "              Open          High           Low        Volume\n",
            "2243   9273.060783   9594.420276   9232.484263  1.784682e+10\n",
            "2244   9525.074608  10144.556717   9525.074608  2.062401e+10\n",
            "2245  10175.923956  11157.345516  10107.035204  2.999520e+10\n",
            "2246  10696.690929  11246.144183  10556.095932  2.099833e+10\n",
            "2247  10853.743838  11065.896018  10610.428082  1.927165e+10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fef6dbc",
      "metadata": {
        "id": "3fef6dbc"
      },
      "source": [
        "## **2. Selección y diseño de modelos**\n",
        "---\n",
        "\n",
        "Seleccione el/los modelo/s a explorar para aplicar sobre el conjunto de datos. Recuerde, la selección del modelo está influenciada por diferentes factores. Si el problema es de análisis de imagen, muy seguramente hay que explorar diversas redes neuronales convolucionales. Si el problema está relacionado con NLP, muy seguramente hay que explorar modelos basados en Tranformers.\n",
        "\n",
        "Además, debe definir cuál es su problema:\n",
        "\n",
        "- **Regresión**: se busca estimar un valor continúo a partir de los datos.\n",
        "- **Clasificación**: permite estimar un valor categórico a partir de los datos.\n",
        "- **Agrupamiento**: permite encontrar grupos de datos similares.\n",
        "- **Otros modelos**: recuerde que dispone de otros tipos de tareas supervisadas y no supervisadas.\n",
        "\n",
        "En cualquier caso los profundos disponibles en _TensorFlow_ constituyen una base sobre la que usted debe definir un clasificador/regresor/_encoder_/_decoder_ final, compuesto de una o más capas densas, con opción de incluir _dropout_ o capas de normalización.\n",
        "\n",
        "Justifique la escogencia y diseño de los modelos a explorar:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Justificación\n",
        "\n",
        "Teniendo en cuenta nuestro objetivo de predecir el precio de cierre de criptomonedas (Bitcoin, para ser más especificos), el modelo que vamos a trabajar es **CNN-LSTM**. Es decir, la idea es combinar modelos de Redes Neuronales Convuncionales con Redes Neuronales Recurrentes.\n",
        "\n",
        "La escogencia de este modelo se da por 3 razones principales:\n",
        "\n",
        "- Debido a la alta volatilidad de las series de tiempo de criptomonedas, es necesario capturar patrones a corto plazo. Para lograr este objetivo, son de suma utilidad los modelos CNN. Por ello, en nuestro modelo se incluiran inicialmente capas convulcionales 1D, por medio del modelo **Conv1D** de TensorFlow.\n",
        "\n",
        "- Adicional a los patrones de corto plazo, es de vital importancia identificar y capturar las tendencias a largo plazo de las series de tiempo, para lo cual recurrimos al modelo **LSTM**. De esta forma, utilizamos las carateristicas extraidas de las capas Conv1D y las pasamos a una capa LSTM.\n",
        "\n",
        "- Si bien podriamos hacer uso de Transformers para capturar más adecuadamente el comportamiento de nuestra serie de tiempo, esto requeriria una gran cantidad de recursos, por lo que, en pro de la eficiencia, consideramos más apropiado recurrir a los modelos mencionados anteriormente.\n",
        "\n"
      ],
      "metadata": {
        "id": "SBH0F3X1aYkn"
      },
      "id": "SBH0F3X1aYkn"
    },
    {
      "cell_type": "markdown",
      "id": "27aa7fd6",
      "metadata": {
        "id": "27aa7fd6"
      },
      "source": [
        "## **3. Implementación de los modelos**\n",
        "---\n",
        "\n",
        "Implemente los modelos descritos anteriormente usando herramientas de _TensorFlow_. Recuerde que puede aplicar técnicas de aumentación de datos, si es necesario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "099040e2",
      "metadata": {
        "id": "099040e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd9b650-2503-4d43-f9fc-0c488ea991f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 2/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 1.0339e-04 - val_loss: 0.0069\n",
            "Epoch 3/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.5598e-05 - val_loss: 0.0082\n",
            "Epoch 4/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0300e-04 - val_loss: 0.0054\n",
            "Epoch 5/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.2132e-05 - val_loss: 0.0071\n",
            "Epoch 6/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.2750e-04 - val_loss: 0.0046\n",
            "Epoch 7/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.5740e-05 - val_loss: 0.0080\n",
            "Epoch 8/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0239e-05 - val_loss: 0.0071\n",
            "Epoch 9/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.4377e-05 - val_loss: 0.0076\n",
            "Epoch 10/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8796e-05 - val_loss: 0.0086\n",
            "Epoch 11/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.7581e-05 - val_loss: 0.0059\n",
            "Epoch 12/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5893e-05 - val_loss: 0.0089\n",
            "Epoch 13/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4547e-05 - val_loss: 0.0122\n",
            "Epoch 14/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.9531e-05 - val_loss: 0.0101\n",
            "Epoch 15/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7084e-05 - val_loss: 0.0076\n",
            "Epoch 16/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.9369e-05 - val_loss: 0.0082\n",
            "Epoch 17/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3059e-05 - val_loss: 0.0128\n",
            "Epoch 18/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.7235e-05 - val_loss: 0.0098\n",
            "Epoch 19/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.5101e-05 - val_loss: 0.0124\n",
            "Epoch 20/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.0469e-05 - val_loss: 0.0098\n",
            "Epoch 21/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.9078e-05 - val_loss: 0.0092\n",
            "Epoch 22/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3947e-05 - val_loss: 0.0090\n",
            "Epoch 23/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3029e-05 - val_loss: 0.0116\n",
            "Epoch 24/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1067e-05 - val_loss: 0.0106\n",
            "Epoch 25/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0807e-05 - val_loss: 0.0139\n",
            "Epoch 26/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.4099e-05 - val_loss: 0.0158\n",
            "Epoch 27/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6754e-05 - val_loss: 0.0127\n",
            "Epoch 28/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.8849e-05 - val_loss: 0.0156\n",
            "Epoch 29/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9901e-05 - val_loss: 0.0120\n",
            "Epoch 30/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3442e-05 - val_loss: 0.0083\n",
            "Epoch 31/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.7785e-05 - val_loss: 0.0116\n",
            "Epoch 32/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0382e-05 - val_loss: 0.0154\n",
            "Epoch 33/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.4891e-05 - val_loss: 0.0133\n",
            "Epoch 34/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.3951e-05 - val_loss: 0.0146\n",
            "Epoch 35/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.6629e-05 - val_loss: 0.0161\n",
            "Epoch 36/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9095e-05 - val_loss: 0.0150\n",
            "Epoch 37/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6263e-05 - val_loss: 0.0169\n",
            "Epoch 38/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0192e-05 - val_loss: 0.0144\n",
            "Epoch 39/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1992e-05 - val_loss: 0.0142\n",
            "Epoch 40/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4671e-05 - val_loss: 0.0154\n",
            "Epoch 41/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4814e-05 - val_loss: 0.0172\n",
            "Epoch 42/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3458e-05 - val_loss: 0.0141\n",
            "Epoch 43/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0647e-05 - val_loss: 0.0180\n",
            "Epoch 44/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7230e-05 - val_loss: 0.0167\n",
            "Epoch 45/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.0623e-05 - val_loss: 0.0178\n",
            "Epoch 46/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3840e-05 - val_loss: 0.0199\n",
            "Epoch 47/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.9538e-05 - val_loss: 0.0207\n",
            "Epoch 48/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.8098e-05 - val_loss: 0.0214\n",
            "Epoch 49/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7957e-05 - val_loss: 0.0196\n",
            "Epoch 50/50\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1372e-05 - val_loss: 0.0206\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Última predicción del precio: [26440.86]\n"
          ]
        }
      ],
      "source": [
        "# ---**INGRESE SU CÓDIGO**---\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Suponemos que tenemos el DataFrame 'dataframes['Bitcoin']' cargado y que contiene el precio de cierre en una columna 'Close'\n",
        "\n",
        "# 1. Preprocesamiento de los datos\n",
        "# Escalar los datos para que estén en el rango [0, 1]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(dataframes['Bitcoin'][['Close']].values)\n",
        "\n",
        "# Definir el tamaño de la ventana de tiempo\n",
        "window_size = 60  # Número de días para mirar hacia atrás en cada predicción\n",
        "\n",
        "# Preparar los datos para el modelo CNN-LSTM\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(window_size, len(data)):\n",
        "    X.append(data[i - window_size:i, 0])\n",
        "    y.append(data[i, 0])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Cambiar la forma de X para que sea compatible con Conv1D y LSTM\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# 2. Definir el modelo CNN-LSTM\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dense(units=1)  # Salida de una única neurona para la predicción del precio de cierre\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 3. Entrenar el modelo\n",
        "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 4. Evaluar el modelo y realizar predicciones\n",
        "# Para predicciones, desnormalizar los valores de salida\n",
        "predicted_prices = model.predict(X)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)  # Convertir de nuevo a los valores originales\n",
        "\n",
        "# Ejemplo: mostrar la última predicción\n",
        "print(\"Última predicción del precio:\", predicted_prices[-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d902f343",
      "metadata": {
        "id": "d902f343"
      },
      "source": [
        "# **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Fabio Augusto Gonzalez](https://dis.unal.edu.co/~fgonza/)\n",
        "* **Asistentes docentes :**\n",
        "  * [Santiago Toledo Cortés](https://sites.google.com/unal.edu.co/santiagotoledo-cortes/)\n",
        "* **Diseño de imágenes:**\n",
        "    - [Mario Andres Rodriguez Triana](mailto:mrodrigueztr@unal.edu.co).\n",
        "* **Coordinador de virtualización:**\n",
        "    - [Edder Hernández Forero](https://www.linkedin.com/in/edder-hernandez-forero-28aa8b207/).\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}